{"version":3,"file":"vendor--micromark.aJPyxAJv.js","sources":["../../../../node_modules/micromark/lib/initialize/content.js","../../../../node_modules/micromark/lib/initialize/document.js","../../../../node_modules/micromark/lib/initialize/flow.js","../../../../node_modules/micromark/lib/initialize/text.js","../../../../node_modules/micromark/lib/constructs.js","../../../../node_modules/micromark/lib/create-tokenizer.js","../../../../node_modules/micromark/lib/parse.js","../../../../node_modules/micromark/lib/postprocess.js","../../../../node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending…\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // …and either is not ended yet…\n        !childFlow.events[index][1].end ||\n        // …or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n\n      // Allow final trailing whitespace.\n      if (context._contentTypeTextTrailing && eventIndex === events.length) {\n        size = 0;\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n        /* c8 ignore next 4 -- used to be used, no longer */\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}"],"names":["content","tokenize","effects","contentStart","attempt","this","parser","constructs","contentInitial","code","consume","enter","exit","factorySpace","lineStart","previous","token","contentType","next","data","markdownLineEnding","document","self","stack","childFlow","childToken","lineStartOffset","continued","start","length","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","undefined","closeFlow","indexBeforeExits","events","point","indexBeforeFlow","type","end","exitContainers","index","splice","slice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","push","flow","_tokenizer","flowContinue","writeToChild","endOfFile","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","disable","null","includes","initial","blankLine","flowInitial","afterConstruct","resolver","resolveAll","createResolver","string","initializeFactory","text","field","resolveAllLineSuffixes","notText","atBreak","list","extraResolver","context","eventIndex","chunks","tabs","bufferIndex","chunk","charCodeAt","_contentTypeTextTrailing","_bufferIndex","_index","column","Object","assign","blockQuote","definition","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","characterReference","characterEscape","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","insideSpan","resolveText","createTokenizer","initialize","from","columnStart","resolveAllConstructs","constructFactory","construct","info","addResult","onsuccessfulcheck","accountForPotentialSkip","fields","pop","value","sliceSerialize","expandTabs","result","atTab","String","fromCharCode","join","serializeChunks","main","state","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","shift","sliceChunks","chunkIndex","go","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","Array","isArray","handleListOfConstructs","map","left","all","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","create","resolve","resolveTo","parse","options","combineExtensions","defaultConstructs","extensions","defined","postprocess","subtokenize","search","preprocess","atCarriageReturn","buffer","encoding","match","startPosition","endPosition","toString","TextDecoder","decode","lastIndex","exec","Math","ceil"],"mappings":"0nBAaO,MAAMA,EAAU,CACrBC,SASF,SAA2BC,GACzB,MAAMC,EAAeD,EAAQE,QAAQC,KAAKC,OAAOC,WAAWC,gBAM5D,SAAoCC,GAClC,GAAa,OAATA,EAEF,YADAP,EAAQQ,QAAQD,GAMlB,OAHAP,EAAQS,MAAM,cACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,cACNC,EAAaX,EAASC,EAAc,aAC/C,IAGE,SAA0BM,GAExB,OADAP,EAAQS,MAAM,aACPG,EAAUL,EACrB,IAnBE,IAAIM,EACJ,OAAOZ,EAqBP,SAASW,EAAUL,GACjB,MAAMO,EAAQd,EAAQS,MAAM,YAAa,CACvCM,YAAa,OACbF,aAMF,OAJIA,IACFA,EAASG,KAAOF,GAElBD,EAAWC,EACJG,EAAKV,EAChB,CAGE,SAASU,EAAKV,GACZ,OAAa,OAATA,GACFP,EAAQU,KAAK,aACbV,EAAQU,KAAK,kBACbV,EAAQQ,QAAQD,IAGdW,EAAmBX,IACrBP,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,aACNE,IAITZ,EAAQQ,QAAQD,GACTU,EACX,CACA,GCvDO,MAAME,EAAW,CACtBpB,SAcF,SAA4BC,GAC1B,MAAMoB,EAAOjB,KAEPkB,EAAQ,GACd,IAEIC,EAEAC,EAEAC,EANAC,EAAY,EAOhB,OAAOC,EAGP,SAASA,EAAMnB,GAWb,GAAIkB,EAAYJ,EAAMM,OAAQ,CAC5B,MAAMC,EAAOP,EAAMI,GAEnB,OADAL,EAAKS,eAAiBD,EAAK,GACpB5B,EAAQE,QAAQ0B,EAAK,GAAGE,aAAcC,EAAkBC,EAAxDhC,CAA4EO,EACzF,CAGI,OAAOyB,EAAmBzB,EAC9B,CAGE,SAASwB,EAAiBxB,GAMxB,GALAkB,IAKIL,EAAKS,eAAeI,WAAY,CAClCb,EAAKS,eAAeI,gBAAaC,EAC7BZ,GACFa,IAKF,MAAMC,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEIW,EAFAC,EAAkBH,EAKtB,KAAOG,KACL,GAAwC,SAApCnB,EAAKiB,OAAOE,GAAiB,IAA0D,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAAsB,CACtGF,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACV,CAEMC,EAAejB,GAGf,IAAIkB,EAAQP,EACZ,KAAOO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAM,IACvBH,GAELK,IAQF,OAJAC,EAAOxB,EAAKiB,OAAQE,EAAkB,EAAG,EAAGnB,EAAKiB,OAAOQ,MAAMT,IAG9DhB,EAAKiB,OAAOV,OAASgB,EACdX,EAAmBzB,EAChC,CACI,OAAOmB,EAAMnB,EACjB,CAGE,SAASyB,EAAmBzB,GAM1B,GAAIkB,IAAcJ,EAAMM,OAAQ,CAI9B,IAAKL,EACH,OAAOwB,EAAkBvC,GAM3B,GAAIe,EAAUyB,kBAAoBzB,EAAUyB,iBAAiBC,SAC3D,OAAOC,EAAU1C,GAQnBa,EAAK8B,UAAYC,QAAQ7B,EAAUyB,mBAAqBzB,EAAU8B,8BACxE,CAII,OADAhC,EAAKS,eAAiB,CAAE,EACjB7B,EAAQqD,MAAMC,EAAoBC,EAAsBC,EAAxDxD,CAA+EO,EAC1F,CAGE,SAASgD,EAAqBhD,GAG5B,OAFIe,GAAWa,IACfO,EAAejB,GACRqB,EAAkBvC,EAC7B,CAGE,SAASiD,EAAsBjD,GAG7B,OAFAa,EAAKhB,OAAOqD,KAAKrC,EAAKsC,MAAMC,MAAQlC,IAAcJ,EAAMM,OACxDH,EAAkBJ,EAAKsC,MAAME,OACtBX,EAAU1C,EACrB,CAGE,SAASuC,EAAkBvC,GAGzB,OADAa,EAAKS,eAAiB,CAAE,EACjB7B,EAAQE,QAAQoD,EAAoBO,EAAmBZ,EAAvDjD,CAAkEO,EAC7E,CAGE,SAASsD,EAAkBtD,GAIzB,OAHAkB,IACAJ,EAAMyC,KAAK,CAAC1C,EAAK2B,iBAAkB3B,EAAKS,iBAEjCiB,EAAkBvC,EAC7B,CAGE,SAAS0C,EAAU1C,GACjB,OAAa,OAATA,GACEe,GAAWa,IACfO,EAAe,QACf1C,EAAQQ,QAAQD,KAGlBe,EAAYA,GAAaF,EAAKhB,OAAO2D,KAAK3C,EAAKsC,OAC/C1D,EAAQS,MAAM,YAAa,CACzBuD,WAAY1C,EACZP,YAAa,OACbF,SAAUU,IAEL0C,EAAa1D,GACxB,CAGE,SAAS0D,EAAa1D,GACpB,OAAa,OAATA,GACF2D,EAAalE,EAAQU,KAAK,cAAc,GACxCgC,EAAe,QACf1C,EAAQQ,QAAQD,IAGdW,EAAmBX,IACrBP,EAAQQ,QAAQD,GAChB2D,EAAalE,EAAQU,KAAK,cAE1Be,EAAY,EACZL,EAAK8B,eAAYhB,EACVR,IAET1B,EAAQQ,QAAQD,GACT0D,EACX,CAUE,SAASC,EAAapD,EAAOqD,GAC3B,MAAMC,EAAShD,EAAKiD,YAAYvD,GAyChC,GAxCIqD,GAAWC,EAAON,KAAK,MAC3BhD,EAAMD,SAAWU,EACbA,IAAYA,EAAWP,KAAOF,GAClCS,EAAaT,EACbQ,EAAUgD,WAAWxD,EAAMY,OAC3BJ,EAAUiD,MAAMH,GAmCZhD,EAAKhB,OAAOqD,KAAK3C,EAAMY,MAAMiC,MAAO,CACtC,IAAIhB,EAAQrB,EAAUe,OAAOV,OAC7B,KAAOgB,KACL,GAEArB,EAAUe,OAAOM,GAAO,GAAGjB,MAAMkC,OAASpC,KAEzCF,EAAUe,OAAOM,GAAO,GAAGF,KAE5BnB,EAAUe,OAAOM,GAAO,GAAGF,IAAImB,OAASpC,GAGtC,OAMJ,MAAMY,EAAmBhB,EAAKiB,OAAOV,OACrC,IAEI6C,EAEAlC,EAJAC,EAAkBH,EAOtB,KAAOG,KACL,GAAwC,SAApCnB,EAAKiB,OAAOE,GAAiB,IAA0D,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAAsB,CACtG,GAAIgC,EAAM,CACRlC,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,KACZ,CACU+B,GAAO,CACjB,CAMM,IAJA9B,EAAejB,GAGfkB,EAAQP,EACDO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAM,IACvBH,GAELK,IAIFC,EAAOxB,EAAKiB,OAAQE,EAAkB,EAAG,EAAGnB,EAAKiB,OAAOQ,MAAMT,IAG9DhB,EAAKiB,OAAOV,OAASgB,CAC3B,CACA,CAQE,SAASD,EAAe+B,GACtB,IAAI9B,EAAQtB,EAAMM,OAGlB,KAAOgB,KAAU8B,GAAM,CACrB,MAAMC,EAAQrD,EAAMsB,GACpBvB,EAAKS,eAAiB6C,EAAM,GAC5BA,EAAM,GAAGhE,KAAKiE,KAAKvD,EAAMpB,EAC/B,CACIqB,EAAMM,OAAS8C,CACnB,CACE,SAAStC,IACPb,EAAUiD,MAAM,CAAC,OACjBhD,OAAaW,EACbZ,OAAYY,EACZd,EAAKS,eAAeI,gBAAaC,CACrC,CACA,GAjUMoB,EAAqB,CACzBvD,SAwUF,SAA2BC,EAAS4E,EAAIC,GAGtC,OAAOlE,EAAaX,EAASA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWc,SAAUyD,EAAIC,GAAM,aAAc1E,KAAKC,OAAOC,WAAWyE,QAAQC,KAAKC,SAAS,qBAAkB9C,EAAY,EACnL,GC5VO,MAAM6B,EAAO,CAClBhE,SASF,SAAwBC,GACtB,MAAMoB,EAAOjB,KACP8E,EAAUjF,EAAQE,QAExBgF,GAMA,SAAuB3E,GACrB,GAAa,OAATA,EAEF,YADAP,EAAQQ,QAAQD,GAOlB,OAJAP,EAAQS,MAAM,mBACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,mBACbU,EAAK2B,sBAAmBb,EACjB+C,CACX,GAdEjF,EAAQE,QAAQC,KAAKC,OAAOC,WAAW8E,YAAaC,EAAgBzE,EAAaX,EAASA,EAAQE,QAAQC,KAAKC,OAAOC,WAAW0D,KAAMqB,EAAgBpF,EAAQE,QAAQJ,EAASsF,IAAkB,gBAClM,OAAOH,EAgBP,SAASG,EAAe7E,GACtB,GAAa,OAATA,EAQJ,OAJAP,EAAQS,MAAM,cACdT,EAAQQ,QAAQD,GAChBP,EAAQU,KAAK,cACbU,EAAK2B,sBAAmBb,EACjB+C,EAPLjF,EAAQQ,QAAQD,EAQtB,CACA,GC9CO,MAAM8E,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3BC,EAAOD,EAAkB,QAQtC,SAASA,EAAkBE,GACzB,MAAO,CACLL,WAAYC,EAAyB,SAAVI,EAAmBC,OAAyB1D,GACvEnC,SAQF,SAAwBC,GACtB,MAAMoB,EAAOjB,KACPE,EAAaF,KAAKC,OAAOC,WAAWsF,GACpCD,EAAO1F,EAAQE,QAAQG,EAAYqB,EAAOmE,GAChD,OAAOnE,EAGP,SAASA,EAAMnB,GACb,OAAOuF,EAAQvF,GAAQmF,EAAKnF,GAAQsF,EAAQtF,EAClD,CAGI,SAASsF,EAAQtF,GACf,GAAa,OAATA,EAMJ,OAFAP,EAAQS,MAAM,QACdT,EAAQQ,QAAQD,GACTU,EALLjB,EAAQQ,QAAQD,EAMxB,CAGI,SAASU,EAAKV,GACZ,OAAIuF,EAAQvF,IACVP,EAAQU,KAAK,QACNgF,EAAKnF,KAIdP,EAAQQ,QAAQD,GACTU,EACb,CAQI,SAAS6E,EAAQvF,GACf,GAAa,OAATA,EACF,OAAO,EAET,MAAMwF,EAAO1F,EAAWE,GACxB,IAAIoC,GAAU,EACd,GAAIoD,EAGF,OAASpD,EAAQoD,EAAKpE,QAAQ,CAC5B,MAAMC,EAAOmE,EAAKpD,GAClB,IAAKf,EAAKf,UAAYe,EAAKf,SAAS8D,KAAKvD,EAAMA,EAAKP,UAClD,OAAO,CAEnB,CAEM,OAAO,CACb,CACA,EACA,CAQA,SAAS0E,EAAeS,GACtB,OAGA,SAAwB3D,EAAQ4D,GAC9B,IAEIxF,EAFAkC,GAAU,EAMd,OAASA,GAASN,EAAOV,aACTO,IAAVzB,EACE4B,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OACpC/B,EAAQkC,EACRA,KAEQN,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OAExCG,IAAUlC,EAAQ,IACpB4B,EAAO5B,GAAO,GAAGgC,IAAMJ,EAAOM,EAAQ,GAAG,GAAGF,IAC5CJ,EAAOO,OAAOnC,EAAQ,EAAGkC,EAAQlC,EAAQ,GACzCkC,EAAQlC,EAAQ,GAElBA,OAAQyB,GAGZ,OAAO8D,EAAgBA,EAAc3D,EAAQ4D,GAAW5D,CAC5D,CACA,CAaA,SAASuD,EAAuBvD,EAAQ4D,GACtC,IAAIC,EAAa,EAEjB,OAASA,GAAc7D,EAAOV,QAC5B,IAAKuE,IAAe7D,EAAOV,QAAyC,eAA/BU,EAAO6D,GAAY,GAAG1D,OAA6D,SAAnCH,EAAO6D,EAAa,GAAG,GAAG1D,KAAiB,CAC9H,MAAMvB,EAAOoB,EAAO6D,EAAa,GAAG,GAC9BC,EAASF,EAAQ5B,YAAYpD,GACnC,IAIImF,EAJAzD,EAAQwD,EAAOxE,OACf0E,GAAgB,EAChB5B,EAAO,EAGX,KAAO9B,KAAS,CACd,MAAM2D,EAAQH,EAAOxD,GACrB,GAAqB,iBAAV2D,EAAoB,CAE7B,IADAD,EAAcC,EAAM3E,OACyB,KAAtC2E,EAAMC,WAAWF,EAAc,IACpC5B,IACA4B,IAEF,GAAIA,EAAa,MACjBA,GAAgB,CAC1B,MAEa,IAAc,IAAVC,EACPF,GAAO,EACP3B,SACK,IAAgB,IAAZ6B,EAEJ,CAEL3D,IACA,KACV,CACA,CAMM,GAHIsD,EAAQO,0BAA4BN,IAAe7D,EAAOV,SAC5D8C,EAAO,GAELA,EAAM,CACR,MAAM3D,EAAQ,CACZ0B,KAAM0D,IAAe7D,EAAOV,QAAUyE,GAAQ3B,EAAO,EAAI,aAAe,oBACxE/C,MAAO,CACL+E,aAAc9D,EAAQ0D,EAAcpF,EAAKS,MAAM+E,aAAeJ,EAC9DK,OAAQzF,EAAKS,MAAMgF,OAAS/D,EAC5BgB,KAAM1C,EAAKwB,IAAIkB,KACfgD,OAAQ1F,EAAKwB,IAAIkE,OAASlC,EAC1Bb,OAAQ3C,EAAKwB,IAAImB,OAASa,GAE5BhC,IAAK,IACAxB,EAAKwB,MAGZxB,EAAKwB,IAAM,IACN3B,EAAMY,OAEPT,EAAKS,MAAMkC,SAAW3C,EAAKwB,IAAImB,OACjCgD,OAAOC,OAAO5F,EAAMH,IAEpBuB,EAAOO,OAAOsD,EAAY,EAAG,CAAC,QAASpF,EAAOmF,GAAU,CAAC,OAAQnF,EAAOmF,IACxEC,GAAc,EAExB,CACMA,GACN,CAEE,OAAO7D,CACT,CC3MO,MAAMlB,EAAW,CACtB,GAAM4E,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMA,EACN,GAAMe,GAIKxG,EAAiB,CAC5B,GAAMyG,GAIK5B,EAAc,CACzB,EAAG,GAAG6B,EACN,EAAG,GAAGA,EACN,GAAMA,GAIKjD,EAAO,CAClB,GAAMkD,EACN,GAAMC,EACN,GAAM,CAACC,EAAiBD,GACxB,GAAME,EACN,GAAMD,EACN,GAAMD,EACN,GAAMG,EACN,IAAOA,GAII7B,EAAS,CACpB,GAAM8B,EACN,GAAMC,GAIK7B,EAAO,CAClB,EAAG,GAAG8B,EACN,EAAG,GAAGA,EACN,EAAG,GAAGA,EACN,GAAMC,EACN,GAAMH,EACN,GAAMI,EACN,GAAM,CAACC,EAAUC,GACjB,GAAMC,EACN,GAAM,CAACC,EAAiBP,GACxB,GAAMQ,EACN,GAAML,EACN,GAAMM,GAIKC,EAAa,CACxBlD,KAAM,CAAC2C,EAAWQ,2EAIY,CAC9BnD,KAAM,CAAC,GAAI,8BAIU,CACrBA,KAAM,wGCvBD,SAASoD,EAAgB/H,EAAQgI,EAAYC,GAElD,IAAI/F,EAAQ,CACVmE,cAAgB,EAChBC,OAAQ,EACR/C,KAAM0E,GAAQA,EAAK1E,MAAQ,EAC3BgD,OAAQ0B,GAAQA,EAAK1B,QAAU,EAC/B/C,OAAQyE,GAAQA,EAAKzE,QAAU,GAGjC,MAAM0E,EAAc,CAAE,EAEhBC,EAAuB,GAE7B,IAAIpC,EAAS,GAET9E,EAAQ,GASZ,MAAMrB,EAAU,CACdE,QAASsI,GAoNX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKL,KAC9B,IArNIhF,MAAOmF,EAAiBI,GACxBpI,QAsJF,SAAiBD,GACXW,EAAmBX,IACrB+B,EAAMqB,OACNrB,EAAMqE,OAAS,EACfrE,EAAMsB,SAAqB,IAAXrD,EAAc,EAAI,EAClCsI,UACStI,IACT+B,EAAMqE,SACNrE,EAAMsB,UAIJtB,EAAMmE,aAAe,EACvBnE,EAAMoE,UAENpE,EAAMmE,eAGFnE,EAAMmE,eAIVN,EAAO7D,EAAMoE,QAAQ/E,SACnBW,EAAMmE,cAAiB,EACvBnE,EAAMoE,WAKVT,EAAQpF,SAAWN,CAIvB,EAtLIE,MAyLF,SAAe+B,EAAMsG,GAGnB,MAAMhI,EAAQgI,GAAU,CAAE,EAK1B,OAJAhI,EAAM0B,KAAOA,EACb1B,EAAMY,MAAQgC,IACduC,EAAQ5D,OAAOyB,KAAK,CAAC,QAAShD,EAAOmF,IACrC5E,EAAMyC,KAAKhD,GACJA,CACX,EAjMIJ,KAoMF,SAAc8B,GACZ,MAAM1B,EAAQO,EAAM0H,MAGpB,OAFAjI,EAAM2B,IAAMiB,IACZuC,EAAQ5D,OAAOyB,KAAK,CAAC,OAAQhD,EAAOmF,IAC7BnF,CACX,EAxMIoC,UAAWsF,EAAiBI,EAAmB,CAC7C1F,WAAW,KAST+C,EAAU,CACd1F,KAAM,KACNsB,eAAgB,CAAE,EAClByC,WA8EF,SAAoB0E,GAClBV,EAAYU,EAAMrF,MAAQqF,EAAMrC,OAChCkC,GACJ,EAhFIxG,OAAQ,GACRqB,MACAtD,SACAS,SAAU,KACVoI,eA4CF,SAAwBnI,EAAOoI,GAC7B,OAuZJ,SAAyB/C,EAAQ+C,GAC/B,IAAIvG,GAAU,EAEd,MAAMwG,EAAS,GAEf,IAAIC,EACJ,OAASzG,EAAQwD,EAAOxE,QAAQ,CAC9B,MAAM2E,EAAQH,EAAOxD,GAErB,IAAIqG,EACJ,GAAqB,iBAAV1C,EACT0C,EAAQ1C,OACH,OAAQA,GACb,KAAO,EAEH0C,EAAQ,KACR,MAEJ,KAAO,EAEHA,EAAQ,KACR,MAEJ,KAAO,EAEHA,EAAQ,OACR,MAEJ,KAAO,EAEHA,EAAQE,EAAa,IAAM,KAC3B,MAEJ,KAAO,EAEH,IAAKA,GAAcE,EAAO,SAC1BJ,EAAQ,IACR,MAEJ,QAGIA,EAAQK,OAAOC,aAAahD,GAGlC8C,GAAoB,IAAZ9C,EACR6C,EAAOrF,KAAKkF,EAChB,CACE,OAAOG,EAAOI,KAAK,GACrB,CAxcWC,CAAgBnF,EAAYvD,GAAQoI,EAC/C,EA7CI7E,cACAE,MAsBF,SAAe1B,GAKb,GAJAsD,EAASrC,EAAKqC,EAAQtD,GACtB4G,IAGkC,OAA9BtD,EAAOA,EAAOxE,OAAS,GACzB,MAAO,GAMT,OAJAgH,EAAUP,EAAY,GAGtBnC,EAAQ5D,OAASiD,EAAWiD,EAAsBtC,EAAQ5D,OAAQ4D,GAC3DA,EAAQ5D,MACnB,GA3BE,IAAIqH,EAAQtB,EAAWrI,SAAS4E,KAAKsB,EAASjG,GAW9C,OAHIoI,EAAW9C,YACbiD,EAAqBzE,KAAKsE,GAErBnC,EA4BP,SAAS5B,EAAYvD,GACnB,OA2WJ,SAAqBqF,EAAQrF,GAC3B,MAAM6I,EAAa7I,EAAMY,MAAMgF,OACzBkD,EAAmB9I,EAAMY,MAAM+E,aAC/BoD,EAAW/I,EAAM2B,IAAIiE,OACrBoD,EAAiBhJ,EAAM2B,IAAIgE,aAEjC,IAAIsD,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAAC5D,EAAOwD,GAAY9G,MAAM+G,EAAkBE,QAC9C,CAEL,GADAC,EAAO5D,EAAOtD,MAAM8G,EAAYE,GAC5BD,GAAmB,EAAI,CACzB,MAAMI,EAAOD,EAAK,GACE,iBAATC,EACTD,EAAK,GAAKC,EAAKnH,MAAM+G,GAGrBG,EAAKE,OAEb,CACQH,EAAiB,GAEnBC,EAAKjG,KAAKqC,EAAO0D,GAAUhH,MAAM,EAAGiH,GAE1C,CACE,OAAOC,CACT,CAtYWG,CAAY/D,EAAQrF,EAC/B,CAGE,SAAS4C,IAEP,MAAM+C,aACJA,EAAYC,OACZA,EAAM/C,KACNA,EAAIgD,OACJA,EAAM/C,OACNA,GACEtB,EACJ,MAAO,CACLmE,eACAC,SACA/C,OACAgD,SACA/C,SAEN,CAuBE,SAAS6F,IAEP,IAAIU,EACJ,KAAO7H,EAAMoE,OAASP,EAAOxE,QAAQ,CACnC,MAAM2E,EAAQH,EAAO7D,EAAMoE,QAG3B,GAAqB,iBAAVJ,EAKT,IAJA6D,EAAa7H,EAAMoE,OACfpE,EAAMmE,aAAe,IACvBnE,EAAMmE,aAAe,GAEhBnE,EAAMoE,SAAWyD,GAAc7H,EAAMmE,aAAeH,EAAM3E,QAC/DyI,EAAG9D,EAAMC,WAAWjE,EAAMmE,oBAG5B2D,EAAG9D,EAEX,CACA,CAUE,SAAS8D,EAAG7J,GAGVmJ,EAAQA,EAAMnJ,EAClB,CAwEE,SAASqI,EAAkByB,EAAG3B,GAC5BA,EAAK4B,SACT,CAUE,SAAS9B,EAAiB+B,EAAUzB,GAClC,OAeA,SAAczI,EAAYmK,EAAaC,GAErC,IAAIC,EAEAC,EAEA5H,EAEA2F,EACJ,OAAOkC,MAAMC,QAAQxK,GACrByK,EAAuBzK,GAAc,aAAcA,EAEnDyK,EAAuB,CAAA,IAUvB,SAA+BC,GAC7B,OAAOrJ,EAGP,SAASA,EAAMnB,GACb,MAAMyK,EAAgB,OAATzK,GAAiBwK,EAAIxK,GAC5B0K,EAAe,OAAT1K,GAAiBwK,EAAIhG,KAKjC,OAAO+F,EAJM,IAGTF,MAAMC,QAAQG,GAAQA,EAAOA,EAAO,CAACA,GAAQ,MAASJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAC5FH,CAA6BvK,EAC9C,CACA,CAvBuE2K,CAAsB7K,GAiCvF,SAASyK,EAAuB/E,GAG9B,OAFA2E,EAAmB3E,EACnB4E,EAAiB,EACG,IAAhB5E,EAAKpE,OACA8I,EAEFU,EAAgBpF,EAAK4E,GACpC,CAUM,SAASQ,EAAgB1C,GACvB,OAGA,SAAelI,GAKbmI,EAgER,WACE,MAAM0C,EAAa1H,IACb2H,EAAgBpF,EAAQpF,SACxByK,EAAwBrF,EAAQlD,iBAChCwI,EAAmBtF,EAAQ5D,OAAOV,OAClC6J,EAAaZ,MAAMvC,KAAKhH,GAC9B,MAAO,CACLgH,KAAMkD,EACNjB,WASF,SAASA,IACPhI,EAAQ8I,EACRnF,EAAQpF,SAAWwK,EACnBpF,EAAQlD,iBAAmBuI,EAC3BrF,EAAQ5D,OAAOV,OAAS4J,EACxBlK,EAAQmK,EACR3C,GACN,CACA,CAzFiB4C,GACP1I,EAAmB0F,EACdA,EAAUiD,UACbzF,EAAQlD,iBAAmB0F,GAK7B,GAAIA,EAAUkD,MAAQ1F,EAAQ7F,OAAOC,WAAWyE,QAAQC,KAAKC,SAASyD,EAAUkD,MAC9E,OAAO9G,IAET,OAAO4D,EAAU1I,SAAS4E,KAI1BmE,EAASlC,OAAOC,OAAOD,OAAOgF,OAAO3F,GAAU6C,GAAU7C,EAASjG,EAAS4E,EAAIC,EAJxE4D,CAI6ElI,EAC9F,CACA,CAGM,SAASqE,EAAGrE,GAGV,OADAgK,EAASxH,EAAkB2F,GACpB8B,CACf,CAGM,SAAS3F,EAAItE,GAGX,OADAmI,EAAK4B,YACCK,EAAiBD,EAAiB/I,OAC/BwJ,EAAgBT,EAAiBC,IAEnCF,CACf,CACA,CACA,CAUE,SAAS9B,EAAUF,EAAWJ,GACxBI,EAAUnD,aAAeiD,EAAqBvD,SAASyD,IACzDF,EAAqBzE,KAAK2E,GAExBA,EAAUoD,SACZjJ,EAAOqD,EAAQ5D,OAAQgG,EAAMpC,EAAQ5D,OAAOV,OAAS0G,EAAMI,EAAUoD,QAAQ5F,EAAQ5D,OAAOQ,MAAMwF,GAAOpC,IAEvGwC,EAAUqD,YACZ7F,EAAQ5D,OAASoG,EAAUqD,UAAU7F,EAAQ5D,OAAQ4D,GAE3D,CA0CE,SAAS4C,IACHvG,EAAMqB,QAAQ2E,GAAehG,EAAMqE,OAAS,IAC9CrE,EAAMqE,OAAS2B,EAAYhG,EAAMqB,MACjCrB,EAAMsB,QAAU0E,EAAYhG,EAAMqB,MAAQ,EAEhD,CACA,CCteO,SAASoI,EAAMC,GACpB,MAKM5L,EAAS,CACbC,WAJF4L,EAAkB,CAACC,MAFFF,GAAW,CAAE,GAEqBG,YAAc,KAK/DrM,QAAS8L,EAAO9L,GAChBsM,QAAS,GACTjL,SAAUyK,EAAOzK,GACjB4C,KAAM6H,EAAO7H,GACbN,KAAM,CAAE,EACR+B,OAAQoG,EAAOpG,GACfE,KAAMkG,EAAOlG,IAEf,OAAOtF,EAQP,SAASwL,EAAO3G,GACd,OAEA,SAAiBoD,GACf,OAAOF,EAAgB/H,EAAQ6E,EAASoD,EAC9C,CACA,CACA,CC3CO,SAASgE,EAAYhK,GAC1B,MAAQiK,EAAYjK,KAGpB,OAAOA,CACT,CCAA,MAAMkK,EAAS,cAMR,SAASC,IACd,IAKIC,EALA9F,EAAS,EACT+F,EAAS,GAEThL,GAAQ,EAGZ,OAIA,SAAsBsH,EAAO2D,EAAUlK,GAErC,MAAM0D,EAAS,GAEf,IAAIyG,EAEA5L,EAEA6L,EAEAC,EAEAvM,EACJyI,EAAQ0D,GAA2B,iBAAV1D,EAAqBA,EAAM+D,WAAa,IAAIC,YAAYL,QAAYzK,GAAW+K,OAAOjE,IAC/G6D,EAAgB,EAChBH,EAAS,GACLhL,IAE0B,QAAxBsH,EAAMzC,WAAW,IACnBsG,IAEFnL,OAAQQ,GAEV,KAAO2K,EAAgB7D,EAAMrH,QAAQ,CAKnC,GAJA4K,EAAOW,UAAYL,EACnBD,EAAQL,EAAOY,KAAKnE,GACpB8D,EAAcF,QAAyB1K,IAAhB0K,EAAMjK,MAAsBiK,EAAMjK,MAAQqG,EAAMrH,OACvEpB,EAAOyI,EAAMzC,WAAWuG,IACnBF,EAAO,CACVF,EAAS1D,EAAMnG,MAAMgK,GACrB,KACR,CACM,GAAa,KAATtM,GAAesM,IAAkBC,GAAeL,EAClDtG,EAAOrC,SACP2I,OAAmBvK,OAUnB,OARIuK,IACFtG,EAAOrC,SACP2I,OAAmBvK,GAEjB2K,EAAgBC,IAClB3G,EAAOrC,KAAKkF,EAAMnG,MAAMgK,EAAeC,IACvCnG,GAAUmG,EAAcD,GAElBtM,GACN,KAAK,EAED4F,EAAOrC,KAAK,OACZ6C,IACA,MAEJ,KAAK,EAID,IAFA3F,EAA+B,EAAxBoM,KAAKC,KAAK1G,EAAS,GAC1BR,EAAOrC,SACA6C,IAAW3F,GAAMmF,EAAOrC,MAAK,GACpC,MAEJ,KAAK,GAEDqC,EAAOrC,SACP6C,EAAS,EACT,MAEJ,QAEI8F,GAAmB,EACnB9F,EAAS,EAIjBkG,EAAgBC,EAAc,CACpC,CACQrK,IACEgK,GAAkBtG,EAAOrC,SACzB4I,GAAQvG,EAAOrC,KAAK4I,GACxBvG,EAAOrC,KAAK,OAEd,OAAOqC,CACX,CACA","x_google_ignoreList":[0,1,2,3,4,5,6,7,8]}